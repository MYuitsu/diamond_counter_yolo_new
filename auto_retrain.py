# -*- coding: utf-8 -*-
"""
Auto Retraining System for Diamond Detection Model
S·ª≠ d·ª•ng feedback data ƒë·ªÉ train l·∫°i model theo chu·∫©n Roboflow
"""

import os
import json
import cv2
import numpy as np
import base64
import shutil
from datetime import datetime
import yaml

# Fix multiprocessing on Windows
import multiprocessing
if __name__ == '__main__':
    multiprocessing.freeze_support()

from ultralytics import YOLO

class AutoRetrainer:
    def __init__(self, feedback_dir="active_learning_data"):
        self.feedback_dir = feedback_dir
        self.training_dir = "diamond_retrain"  # T√™n folder theo chu·∫©n Roboflow
        self.current_model_path = "runs/segment/success1/weights/best.pt"
        
        # T·∫°o folder structure theo chu·∫©n Roboflow
        self.setup_roboflow_structure()
    
    def setup_roboflow_structure(self):
        """T·∫°o c·∫•u tr√∫c folder theo chu·∫©n Roboflow"""
        folders = [
            f"{self.training_dir}/train/images",
            f"{self.training_dir}/train/labels", 
            f"{self.training_dir}/valid/images",
            f"{self.training_dir}/valid/labels",
            f"{self.training_dir}/test/images",
            f"{self.training_dir}/test/labels"
        ]
        
        for folder in folders:
            os.makedirs(folder, exist_ok=True)
        
        print(f"‚úÖ Created Roboflow structure: {self.training_dir}/")
    
    def process_feedback_to_roboflow(self, task_type="detect"):
        """X·ª≠ l√Ω feedback data th√†nh format Roboflow chu·∫©n"""
        annotation_files = [f for f in os.listdir(f"{self.feedback_dir}/annotations") 
                          if f.endswith('.json')]
        
        if not annotation_files:
            print("‚ùå Kh√¥ng c√≥ feedback data ƒë·ªÉ train!")
            return False
        
        print(f"üìä Processing {len(annotation_files)} feedback files to Roboflow format ({task_type})...")
        
        train_count = 0
        valid_count = 0
        test_count = 0
        
        for i, file in enumerate(annotation_files):
            try:
                # Load feedback data
                with open(f"{self.feedback_dir}/annotations/{file}", 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # Ph√¢n chia dataset theo t·ªâ l·ªá chu·∫©n Roboflow:
                # Train: 70%, Valid: 25%, Test: 5%
                if i % 20 == 0:  # 5% for test
                    split = "test"
                    test_count += 1
                elif i % 4 == 0:  # 25% for valid  
                    split = "valid"
                    valid_count += 1
                else:  # 70% for train
                    split = "train"
                    train_count += 1
                
                # Process image and annotations with task type
                success = self.create_roboflow_annotation(data, split, task_type)
                
                if success:
                    print(f"‚úÖ Processed {file} ‚Üí {split}")
                        
            except Exception as e:
                print(f"‚ö†Ô∏è Error processing {file}: {e}")
                continue
        
        print(f"üìà Dataset created: {train_count} train, {valid_count} valid, {test_count} test")
        return train_count > 0
    
    def create_roboflow_annotation(self, feedback_data, split, task_type="detect"):
        """T·∫°o annotation Roboflow t·ª´ feedback data - support c·∫£ detect v√† segment"""
        try:
            # Get corrected predictions
            predictions = feedback_data.get('predictions', [])
            corrections = feedback_data.get('user_corrections', {})
            
            # ∆Øu ti√™n s·ª≠ d·ª•ng true_positives n·∫øu c√≥
            if 'true_positives' in corrections:
                true_positives = corrections['true_positives']
            else:
                # Fallback: t√≠nh t·ª´ predictions - false_positives
                false_positives = set(corrections.get('false_positives', []))
                true_positives = [pred for i, pred in enumerate(predictions) if i not in false_positives]
            
            missed_objects = corrections.get('missed_objects', [])
            
            # Load image
            image_path = feedback_data.get('image_path')
            if not image_path or not os.path.exists(image_path):
                return False
            
            image = cv2.imread(image_path)
            if image is None:
                return False
            
            h, w = image.shape[:2]
            
            # Create file names
            timestamp = feedback_data.get('timestamp', datetime.now().strftime("%Y%m%d_%H%M%S"))
            img_name = f"diamond_{timestamp}.jpg"
            label_name = f"diamond_{timestamp}.txt"
            
            # Copy image to Roboflow folder structure
            img_dst = f"{self.training_dir}/{split}/images/{img_name}"
            shutil.copy2(image_path, img_dst)
            
            # Create YOLO annotation
            annotations = []
            
            # Add TRUE POSITIVES
            for pred in true_positives:
                if task_type == "segment":
                    # Segmentation format: class x1 y1 x2 y2 x3 y3 x4 y4 (polygon)
                    x1 = pred['x'] / w
                    y1 = pred['y'] / h
                    x2 = (pred['x'] + pred['w']) / w
                    y2 = pred['y'] / h
                    x3 = (pred['x'] + pred['w']) / w
                    y3 = (pred['y'] + pred['h']) / h
                    x4 = pred['x'] / w
                    y4 = (pred['y'] + pred['h']) / h
                    
                    polygon = f"0 {x1:.6f} {y1:.6f} {x2:.6f} {y2:.6f} {x3:.6f} {y3:.6f} {x4:.6f} {y4:.6f}"
                    annotations.append(polygon)
                else:
                    # Detection format: class x_center y_center width height
                    x_center = (pred['x'] + pred['w'] / 2) / w
                    y_center = (pred['y'] + pred['h'] / 2) / h
                    width = pred['w'] / w
                    height = pred['h'] / h
                    
                    annotations.append(f"0 {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}")
            
            # Add MISSED OBJECTS
            for missed in missed_objects:
                if task_type == "segment":
                    # Segmentation format
                    x1 = missed['x'] / w
                    y1 = missed['y'] / h
                    x2 = (missed['x'] + missed['w']) / w
                    y2 = missed['y'] / h
                    x3 = (missed['x'] + missed['w']) / w
                    y3 = (missed['y'] + missed['h']) / h
                    x4 = missed['x'] / w
                    y4 = (missed['y'] + missed['h']) / h
                    
                    polygon = f"0 {x1:.6f} {y1:.6f} {x2:.6f} {y2:.6f} {x3:.6f} {y3:.6f} {x4:.6f} {y4:.6f}"
                    annotations.append(polygon)
                else:
                    # Detection format
                    x_center = (missed['x'] + missed['w'] / 2) / w
                    y_center = (missed['y'] + missed['h'] / 2) / h
                    width = missed['w'] / w
                    height = missed['h'] / h
                    
                    annotations.append(f"0 {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}")
            
            # Save annotation file
            label_path = f"{self.training_dir}/{split}/labels/{label_name}"
            with open(label_path, 'w') as f:
                f.write('\n'.join(annotations))
            
            print(f"Created {task_type} annotation with {len(true_positives)} TP + {len(missed_objects)} missed = {len(annotations)} total")
            return True
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error creating annotation: {e}")
            return False
    
    def create_roboflow_yaml(self):
        """T·∫°o data.yaml theo chu·∫©n Roboflow"""
        yaml_content = {
            # ƒê∆∞·ªùng d·∫´n theo chu·∫©n Roboflow
            'path': os.path.abspath(self.training_dir),
            'train': 'train/images',
            'val': 'valid/images', 
            'test': 'test/images',
            
            # Number of classes
            'nc': 1,
            
            # Class names
            'names': ['diamond']
        }
        
        yaml_path = f"{self.training_dir}/data.yaml"
        with open(yaml_path, 'w') as f:
            yaml.dump(yaml_content, f, default_flow_style=False)
        
        print(f"üìÑ Created Roboflow data.yaml: {yaml_path}")
        return yaml_path
    
    def start_yolo_training(self, epochs=100, model_size='n'):
        """B·∫Øt ƒë·∫ßu training theo l·ªánh YOLO chu·∫©n v·ªõi Transfer Learning"""
        try:
            print("üöÄ Starting YOLO training with Roboflow data...")
            
            # LU√îN S·ª¨ D·ª§NG DETECTION MODEL ƒë·ªÉ tr√°nh segmentation issues
            # Detection model ƒë∆°n gi·∫£n h∆°n v√† √≠t l·ªói h∆°n
            model_variants = {
                'n': 'yolov8n.pt',  # detection nano 
                's': 'yolov8s.pt',  # detection small
                'm': 'yolov8m.pt',  # detection medium
                'l': 'yolov8l.pt',  # detection large
                'x': 'yolov8x.pt'   # detection extra large
            }
            
            # Check for existing model first
            current_model = "runs/segment/success1/weights/best.pt"
            if os.path.exists(current_model):
                print(f"üì¶ Found existing model: {current_model}")
                print("ÔøΩ Converting to detection training for stability...")
                training_type = "transfer_learning"
            else:
                training_type = "from_pretrained"
            
            model_name = model_variants.get(model_size, 'yolov8n.pt')
            print(f"üì¶ Using detection model: {model_name}")
            task_type = "detect"
            
            # Process feedback data to Roboflow format with correct task type
            if not self.process_feedback_to_roboflow(task_type):
                return False
            
            # Create data.yaml
            yaml_path = self.create_roboflow_yaml()
            
            # Load v√† train model theo chu·∫©n YOLO
            model = YOLO(model_name)
            
            # T·∫°o timestamp cho t√™n training run
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            run_name = f'diamond_{training_type}_{timestamp}_ep{epochs}_{model_size}'
            
            # Train command v·ªõi Transfer Learning parameters
            print(f"üèãÔ∏è Training: task=detect mode=train model={model_name} data={yaml_path} epochs={epochs}")
            print(f"üß† Training type: {training_type}")
            print(f"üìÅ Results will be saved to: runs/detect/{run_name}")
            
            # Training parameters ƒë∆∞·ª£c t·ªëi ∆∞u cho memory efficiency v√† Windows
            train_params = {
                'data': yaml_path,
                'epochs': epochs,
                'imgsz': 320,  # Gi·∫£m image size ƒë·ªÉ ti·∫øt ki·ªám memory
                'device': 'cpu',  # Force CPU ƒë·ªÉ tr√°nh CUDA memory issues
                'project': 'runs/detect',  # Change to detect project
                'name': run_name,
                'exist_ok': True,
                'plots': False,  # T·∫Øt plots ƒë·ªÉ ti·∫øt ki·ªám memory
                'save': True,
                'workers': 1,  # Gi·∫£m workers ƒë·ªÉ tr√°nh multiprocessing issues
                'batch': 1,  # Batch size nh·ªè ƒë·ªÉ ti·∫øt ki·ªám memory
                'amp': False,  # T·∫Øt automatic mixed precision
            }
            
            # N·∫øu l√† transfer learning, d√πng learning rate th·∫•p h∆°n
            if training_type == "transfer_learning":
                train_params.update({
                    'lr0': 0.001,      # Lower initial learning rate cho fine-tuning
                    'lrf': 0.01,       # Lower final learning rate 
                    'warmup_epochs': 3, # Fewer warmup epochs
                    'patience': 15,    # More patience for convergence
                    'close_mosaic': 10 # Close mosaic augmentation earlier
                })
                print("üîß Using Transfer Learning parameters: lr0=0.001, lrf=0.01, patience=15")
            
            results = model.train(**train_params)
            
            # Update model n·∫øu training th√†nh c√¥ng
            if results:
                new_model_path = f"{results.save_dir}/weights/best.pt"
                if os.path.exists(new_model_path):
                    print(f"‚úÖ New model trained: {new_model_path}")
                    
                    # Backup old model n·∫øu c√≥
                    if training_type == "transfer_learning":
                        backup_dir = "runs/detect/model_backups"  # Change to detect
                        os.makedirs(backup_dir, exist_ok=True)
                        backup_path = f"{backup_dir}/backup_{timestamp}_best.pt"
                        if os.path.exists(current_model):
                            shutil.copy2(current_model, backup_path)
                            print(f"üíæ Backed up old model: {backup_path}")
                    
                    # T·∫°o symlink ho·∫∑c copy ƒë·ªÉ ap.py c√≥ th·ªÉ t·ª± ƒë·ªông load
                    latest_model_dir = "runs/detect/latest_retrain"  # Change to detect
                    os.makedirs(latest_model_dir, exist_ok=True)
                    
                    latest_model_path = f"{latest_model_dir}/best.pt"
                    shutil.copy2(new_model_path, latest_model_path)
                    
                    # L∆∞u th√¥ng tin v·ªÅ model m·ªõi nh·∫•t
                    model_info = {
                        "timestamp": timestamp,
                        "model_path": new_model_path,
                        "model_size": model_size,
                        "epochs": epochs,
                        "training_type": training_type,
                        "base_model": model_name,
                        "training_data": f"feedback samples from {len(os.listdir(f'{self.feedback_dir}/annotations'))} files",
                        "created_at": datetime.now().isoformat()
                    }
                    
                    with open(f"{latest_model_dir}/model_info.json", 'w') as f:
                        json.dump(model_info, f, indent=2)
                    
                    print(f"üîó Latest model symlinked to: {latest_model_path}")
                    print(f"ÔøΩ Model info saved to: {latest_model_dir}/model_info.json")
                    
                    return True
            
            return False
            
        except Exception as e:
            print(f"‚ùå Training failed: {e}")
            return False
    
    def check_gpu(self):
        """Ki·ªÉm tra GPU availability"""
        try:
            import torch
            return torch.cuda.is_available()
        except:
            return False
    
    def get_training_stats(self):
        """L·∫•y th·ªëng k√™ training data"""
        feedback_files = len([f for f in os.listdir(f"{self.feedback_dir}/annotations") 
                            if f.endswith('.json')]) if os.path.exists(f"{self.feedback_dir}/annotations") else 0
        
        train_images = len([f for f in os.listdir(f"{self.training_dir}/train/images") 
                          if f.lower().endswith(('.jpg', '.jpeg', '.png'))]) if os.path.exists(f"{self.training_dir}/train/images") else 0
        
        valid_images = len([f for f in os.listdir(f"{self.training_dir}/valid/images") 
                          if f.lower().endswith(('.jpg', '.jpeg', '.png'))]) if os.path.exists(f"{self.training_dir}/valid/images") else 0
        
        test_images = len([f for f in os.listdir(f"{self.training_dir}/test/images") 
                         if f.lower().endswith(('.jpg', '.jpeg', '.png'))]) if os.path.exists(f"{self.training_dir}/test/images") else 0
        
        return {
            "feedback_files": feedback_files,
            "train_images": train_images,
            "valid_images": valid_images,
            "test_images": test_images,
            "total_samples": train_images + valid_images + test_images
        }

def main():
    """Main function ƒë·ªÉ ch·∫°y retraining theo chu·∫©n Roboflow"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Auto Retrainer for Diamond Detection (Roboflow Style)')
    parser.add_argument('--epochs', type=int, default=100, help='Number of training epochs (default: 100)')
    parser.add_argument('--model', type=str, default='n', choices=['n', 's', 'm', 'l', 'x'], 
                       help='Model size: n(ano), s(mall), m(edium), l(arge), x(tra large)')
    parser.add_argument('--auto', action='store_true', help='Auto run without user input')
    args = parser.parse_args()
    
    retrainer = AutoRetrainer()
    
    print("üéØ DIAMOND DETECTION AUTO RETRAINER (ROBOFLOW STYLE)")
    print("=" * 60)
    
    # Get stats
    stats = retrainer.get_training_stats()
    print(f"üìä Current stats:")
    print(f"   - Feedback files: {stats['feedback_files']}")
    print(f"   - Total samples: {stats['total_samples']}")
    print(f"   - Train: {stats['train_images']}, Valid: {stats['valid_images']}, Test: {stats['test_images']}")
    
    if stats['feedback_files'] == 0:
        print("‚ùå No feedback data available. Please collect feedback first!")
        print("üí° Use the web interface to submit feedback on predictions")
        return
    
    # Model size info
    model_info = {
        'n': 'YOLOv8n-seg (Nano) - Fast, small model',
        's': 'YOLOv8s-seg (Small) - Balanced speed/accuracy', 
        'm': 'YOLOv8m-seg (Medium) - Better accuracy',
        'l': 'YOLOv8l-seg (Large) - High accuracy',
        'x': 'YOLOv8x-seg (X-Large) - Best accuracy'
    }
    
    print(f"ü§ñ Selected model: {model_info[args.model]}")
    print(f"‚è±Ô∏è Training epochs: {args.epochs}")
    
    # Auto mode ho·∫∑c ask user
    if not args.auto:
        print(f"\nü§î This will train a new model using:")
        print(f"   üìÅ Dataset: diamond_retrain/ (Roboflow format)")
        print(f"   üß† Model: yolov8{args.model}-seg.pt")
        print(f"   üîÑ Epochs: {args.epochs}")
        print(f"   üìä Data split: 70% train, 25% valid, 5% test")
        
        response = input(f"\nContinue with training? (y/n): ").lower()
        if response != 'y':
            print("‚ùå Training cancelled")
            return
    else:
        print(f"üöÄ Auto mode: Starting Roboflow-style training...")
    
    # Start retraining v·ªõi method m·ªõi
    success = retrainer.start_yolo_training(epochs=args.epochs, model_size=args.model)
    
    if success:
        print("\nüéâ TRAINING COMPLETED SUCCESSFULLY!")
        print("‚úÖ Model has been updated with user feedback")
        print("üîÑ Restart the Flask application to use the new model")
        print("üìÅ Training results saved in runs/segment/retrain_roboflow_*/")
    else:
        print("\n‚ùå TRAINING FAILED!")
        print("Please check the logs for errors")
        print("üí° Make sure you have enough feedback data and GPU/CPU resources")

if __name__ == "__main__":
    main()
