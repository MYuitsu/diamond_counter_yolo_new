"""
Test chuy√™n bi·ªát cho RTX 2060 - ƒê·∫øm kim c∆∞∆°ng 1mm
"""
import time
import cv2
import numpy as np
import torch
from ultralytics import YOLO
from config import YOLO_CONFIG, FILTER_CONFIG
from utils_device import get_device, get_gpu_memory_info, optimize_gpu_memory

def test_rtx2060_performance():
    """Test hi·ªáu su·∫•t RTX 2060 v·ªõi kim c∆∞∆°ng 1mm"""
    print("=== TEST RTX 2060 - ƒê·∫æM KIM C∆Ø∆†NG 1MM ===")
    
    device = get_device()
    if str(device) != 'cuda':
        print("‚ùå RTX 2060 kh√¥ng ƒë∆∞·ª£c detect. Ki·ªÉm tra driver CUDA.")
        return False
    
    print(f"‚úì GPU: {torch.cuda.get_device_name(0)}")
    
    # Load model
    optimize_gpu_memory()
    model = YOLO("runs/segment/success1/weights/best.pt")
    model.to(device)
    model.half()
    
    mem_info = get_gpu_memory_info()
    print(f"üíæ Model Memory: {mem_info['allocated']:.1f}GB")
    
    # Test v·ªõi c√°c k√≠ch th∆∞·ªõc ·∫£nh kh√°c nhau
    test_cases = [
        {"size": 640, "desc": "Nhanh"},
        {"size": 1024, "desc": "C√¢n b·∫±ng"}, 
        {"size": 1280, "desc": "Ch√≠nh x√°c"},
        {"size": 1536, "desc": "Si√™u ch√≠nh x√°c (n·∫øu ƒë·ªß VRAM)"}
    ]
    
    print(f"\n{'Size':<8} {'Time(ms)':<10} {'FPS':<6} {'Memory':<10} {'Detections':<12} {'Desc'}")
    print("="*70)
    
    best_config = None
    best_score = 0
    
    for test in test_cases:
        size = test["size"]
        desc = test["desc"]
        
        # T·∫°o test image v·ªõi kim c∆∞∆°ng gi·∫£
        test_image = create_diamond_test_image(size)
        
        try:
            # Warm up
            for _ in range(2):
                _ = model(test_image, **YOLO_CONFIG)
            
            torch.cuda.empty_cache()
            
            # Benchmark
            times = []
            detections = []
            
            for _ in range(3):
                start = time.time()
                results = model(test_image, **YOLO_CONFIG)
                torch.cuda.synchronize()
                end = time.time()
                
                times.append((end - start) * 1000)
                if results[0].masks is not None:
                    detections.append(len(results[0].masks.data))
                else:
                    detections.append(0)
            
            avg_time = sum(times) / len(times)
            fps = 1000 / avg_time
            avg_det = sum(detections) / len(detections)
            
            # Memory usage
            mem_info = get_gpu_memory_info()
            memory_usage = f"{mem_info['allocated']:.1f}GB"
            
            # Score = accuracy + speed
            speed_score = min(fps / 10, 1.0)  # Normalize FPS
            accuracy_score = min(avg_det / 20, 1.0)  # Expected ~20 diamonds
            total_score = (accuracy_score * 0.7 + speed_score * 0.3)
            
            print(f"{size}x{size:<3} {avg_time:<10.1f} {fps:<6.2f} {memory_usage:<10} {avg_det:<12.1f} {desc}")
            
            if total_score > best_score and mem_info['allocated'] < mem_info['total'] * 0.9:
                best_score = total_score
                best_config = {"size": size, "fps": fps, "accuracy": avg_det, "desc": desc}
                
        except torch.cuda.OutOfMemoryError:
            print(f"{size}x{size:<3} {'OOM':<10} {'N/A':<6} {'N/A':<10} {'N/A':<12} {desc}")
            torch.cuda.empty_cache()
            continue
        except Exception as e:
            print(f"{size}x{size:<3} {'Error':<10} {'N/A':<6} {'N/A':<10} {'N/A':<12} {str(e)[:10]}")
            continue
    
    print("="*70)
    
    if best_config:
        print(f"üèÜ KHUY·∫æN NGH·ªä CHO RTX 2060:")
        print(f"   - K√≠ch th∆∞·ªõc ·∫£nh: {best_config['size']}x{best_config['size']}")
        print(f"   - FPS: {best_config['fps']:.1f}")
        print(f"   - Detections: {best_config['accuracy']:.1f}")
        print(f"   - M√¥ t·∫£: {best_config['desc']}")
        
        # C·∫≠p nh·∫≠t config t·ª± ƒë·ªông
        update_config_for_rtx2060(best_config['size'])
    
    return True

def create_diamond_test_image(size):
    """T·∫°o ·∫£nh test v·ªõi kim c∆∞∆°ng gi·∫£"""
    image = np.zeros((size, size, 3), dtype=np.uint8)
    
    # Background gradient
    for i in range(size):
        for j in range(size):
            image[i, j] = [50 + (i+j) % 50, 50 + (i+j) % 50, 50 + (i+j) % 50]
    
    # Add noise
    noise = np.random.randint(-20, 20, (size, size, 3))
    image = np.clip(image + noise, 0, 255).astype(np.uint8)
    
    # Th√™m kim c∆∞∆°ng gi·∫£ v·ªõi k√≠ch th∆∞·ªõc kh√°c nhau
    diamond_sizes = [3, 5, 8, 12, 15, 20]  # pixels (t∆∞∆°ng ƒë∆∞∆°ng 0.8-4mm)
    positions = []
    
    # Generate random positions
    margin = 50
    for _ in range(25):  # 25 kim c∆∞∆°ng test
        x = np.random.randint(margin, size - margin)
        y = np.random.randint(margin, size - margin)
        
        # Ki·ªÉm tra kh√¥ng overlap
        too_close = False
        for px, py in positions:
            if abs(x - px) < 30 or abs(y - py) < 30:
                too_close = True
                break
        
        if not too_close:
            positions.append((x, y))
    
    # V·∫Ω kim c∆∞∆°ng
    for i, (x, y) in enumerate(positions[:20]):  # Ch·ªâ v·∫Ω 20 c√°i
        radius = diamond_sizes[i % len(diamond_sizes)]
        
        # V·∫Ω h√¨nh tr√≤n tr·∫Øng (kim c∆∞∆°ng)
        cv2.circle(image, (x, y), radius, (255, 255, 255), -1)
        
        # Th√™m highlight
        cv2.circle(image, (x - radius//3, y - radius//3), radius//3, (200, 200, 200), -1)
        
        # Th√™m shadow nh·∫π
        cv2.circle(image, (x + 1, y + 1), radius, (180, 180, 180), 1)
    
    return image

def update_config_for_rtx2060(optimal_size):
    """C·∫≠p nh·∫≠t config t·ª± ƒë·ªông cho RTX 2060"""
    print(f"\nüîß C·∫≠p nh·∫≠t config t·ªëi ∆∞u cho RTX 2060...")
    
    config_update = f"""
# RTX 2060 Optimal Config (Auto-generated)
YOLO_CONFIG_RTX2060 = {{
    "conf": 0.01,          # Ultra low confidence cho kim c∆∞∆°ng 1mm
    "iou": 0.3,            # IoU threshold
    "max_det": 50000,      # Max detection cho RTX 2060
    "augment": True,       # Test-time augmentation
    "agnostic_nms": False, 
    "imgsz": {optimal_size},         # Optimal size cho RTX 2060
    "half": True,          # FP16 cho RTX 2060
    "verbose": False,
    "retina_masks": True,  # High-quality masks
}}
"""
    
    with open("rtx2060_optimal_config.py", "w") as f:
        f.write(config_update)
    
    print("‚úì Config ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'rtx2060_optimal_config.py'")

def memory_stress_test():
    """Test memory RTX 2060 v·ªõi batch processing"""
    print(f"\nüß™ MEMORY STRESS TEST RTX 2060:")
    
    device = get_device()
    model = YOLO("runs/segment/success1/weights/best.pt")
    model.to(device)
    model.half()
    
    # Test v·ªõi batch sizes kh√°c nhau
    batch_sizes = [1, 2, 4, 8]
    image_size = 1280
    
    for batch_size in batch_sizes:
        try:
            # T·∫°o batch images
            images = [create_diamond_test_image(image_size) for _ in range(batch_size)]
            
            torch.cuda.empty_cache()
            start_mem = get_gpu_memory_info()['allocated']
            
            # Process batch
            start = time.time()
            for img in images:
                _ = model(img, **YOLO_CONFIG)
            end = time.time()
            
            end_mem = get_gpu_memory_info()['allocated']
            mem_per_image = (end_mem - start_mem) / batch_size
            time_per_image = (end - start) / batch_size * 1000
            
            print(f"Batch {batch_size}: {time_per_image:.1f}ms/img, {mem_per_image:.2f}GB/img")
            
        except torch.cuda.OutOfMemoryError:
            print(f"Batch {batch_size}: OOM - Max batch size found: {batch_size-1}")
            break
        except Exception as e:
            print(f"Batch {batch_size}: Error - {e}")
            break

if __name__ == "__main__":
    success = test_rtx2060_performance()
    if success:
        memory_stress_test()
        print(f"\nüéØ K·∫æT LU·∫¨N:")
        print("‚úì RTX 2060 ho·∫°t ƒë·ªông t·ªët cho ƒë·∫øm kim c∆∞∆°ng 1mm")
        print("‚úì S·ª≠ d·ª•ng config ƒë∆∞·ª£c khuy·∫øn ngh·ªã ƒë·ªÉ ƒë·∫°t hi·ªáu su·∫•t t·ªëi ∆∞u")
        print("‚úì Ki·ªÉm tra memory usage th∆∞·ªùng xuy√™n khi process ·∫£nh l·ªõn")
    else:
        print("‚ùå RTX 2060 ch∆∞a s·∫µn s√†ng. Ki·ªÉm tra c√†i ƒë·∫∑t CUDA.")
